{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97e4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as pl\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7354f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_classifier(dataset,classifier,labels):\n",
    "\n",
    "    kf = KFold(n_splits=3,random_state=50,shuffle=True)\n",
    "    confusion_mat = np.zeros((2,2))\n",
    "    recall = 0\n",
    "    for training_ids,test_ids in kf.split(dataset):\n",
    "        training_set = dataset[training_ids]\n",
    "        training_labels = labels[training_ids]\n",
    "        test_set = dataset[test_ids]\n",
    "        test_labels = labels[test_ids]\n",
    "        classifier.fit(training_set,training_labels)\n",
    "        predicted_labels = classifier.predict(test_set)\n",
    "        confusion_mat+=confusion_matrix(test_labels,predicted_labels)\n",
    "        recall += recall_score(test_labels, predicted_labels)\n",
    "    recall/=3\n",
    "    print(confusion_mat)\n",
    "    print(recall)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46013a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"nba_logreg.csv\", sep=\";\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd93b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#First, let's see what feature seem to make the greatest impact on the Target feature :\n",
    "correlation = df.corr()\n",
    "\n",
    "pl.figure(figsize=(10,10))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "pl.title(\"Corr√©lation entre les features et la variable cible\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a290c",
   "metadata": {},
   "source": [
    "Unsurprinsingly, what seems to make a difference is mainly the games the player played (i.e. a player has a better shot at making 5 seasons if one of the seasons he played in, he played a lot of games, insinuating he was a positive asset for his team)\n",
    "Let's visually see that through a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed64bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue' if val == 1 else 'red' for val in df['TARGET_5Yrs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba2de1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl.scatter(df['GP'],df['FG%'],c=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be75918",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract names, labels, features names and values\n",
    "names = df['Name'].values.tolist() # players names\n",
    "labels = df['TARGET_5Yrs'].values # labels\n",
    "paramset = df.drop(['TARGET_5Yrs','Name'],axis=1).columns.values\n",
    "df_vals = df.drop(['TARGET_5Yrs','Name'],axis=1).values\n",
    "\n",
    "# replacing Nan values (only present when no 3 points attempts have been performed by a player)\n",
    "for x in np.argwhere(np.isnan(df_vals)):\n",
    "    df_vals[x]=0.0\n",
    "\n",
    "# normalize dataset\n",
    "X = MinMaxScaler().fit_transform(df_vals)\n",
    "\n",
    "#example of scoring with support vector classifier\n",
    "score_classifier(X,SVC(),labels)\n",
    "\n",
    "# TODO build a training set and choose a classifier which maximize recall score returned by the score_classifier function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323fd983",
   "metadata": {},
   "source": [
    "Now we shall build a new classifier with the intent of getting higher that ~82% accuracy in our prediction.\n",
    "I chose random forests because it's both effective and quite easy to set up and modify, while not beeing too demanding in resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072ca20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We make 30 different distributions to balance the randomness in the sampling\n",
    "n = 30\n",
    "scores = []\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_vals, labels, test_size=0.25, random_state=i)\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=i, max_depth=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = score_classifier(X_test, clf,labels)\n",
    "    \n",
    "    scores.append(accuracy)\n",
    "\n",
    "mean_scores = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf9f765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl.plot(range(n),scores)\n",
    "pl.axhline(mean_scores, color='red', linestyle='--', label=f'Moyenne = {mean_scores:.2f}')\n",
    "\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a152665f",
   "metadata": {},
   "source": [
    "##### We get a 92% accuracy with this classifier, and this result is quite robust to variance in samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5092743",
   "metadata": {},
   "source": [
    "##### Now let's see what feature the random forest classifier uses to make it's prediction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da3637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "\n",
    "# Rank features by importance\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "print(\"Feature importance :\")\n",
    "for i in range(X.shape[1]):\n",
    "    print(f\"Feature {indices[i]} : {importances[indices[i]]}\")\n",
    "    \n",
    "nom_indices = [paramset[i] for i in indices]    \n",
    "\n",
    "pl.figure(figsize=(15, 8))\n",
    "pl.title(\"Feature importance :\")\n",
    "pl.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
    "pl.xticks(range(X.shape[1]), nom_indices)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7f8817",
   "metadata": {},
   "source": [
    "##### Finally, let's pack it into a usable API so users can put the season of 1 player and ask the model whether that player has a chance of playing for more than 5 years in the league"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b57ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "#save the model\n",
    "joblib.dump(clf, 'decision_tree_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a68c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "model = joblib.load('decision_tree_model.pkl')\n",
    "\n",
    "#POST request the stats required\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "\n",
    "    \n",
    "    features = np.array([[\n",
    "        data.get('GP'),\n",
    "        data.get('MIN'),\n",
    "        data.get('PTS'),\n",
    "        data.get('FGM'),\n",
    "        data.get('FGA'),\n",
    "        data.get('FG%'),\n",
    "        data.get('3PM'),\n",
    "        data.get('3P%'),\n",
    "        data.get('FTM'),\n",
    "        data.get('FTA'),\n",
    "        data.get('FT%'),\n",
    "        data.get('OREB'),\n",
    "        data.get('DREB'),\n",
    "        data.get('REB'),\n",
    "        data.get('AST'),\n",
    "        data.get('STL'),\n",
    "        data.get('BLK'),\n",
    "        data.get('TOV'),\n",
    "    ]])\n",
    "\n",
    "    #make the model predict\n",
    "    prediction = model.predict(features)\n",
    "\n",
    "    #return said prediction\n",
    "    return jsonify({'prediction': int(prediction[0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394da3db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
